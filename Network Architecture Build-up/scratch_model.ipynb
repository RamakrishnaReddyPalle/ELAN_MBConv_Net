{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HybridNet Scratch Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **Conv layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_i(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
    "        super(Conv_i, self).__init__()\n",
    "        \n",
    "        # Convolution layer\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding=padding, \n",
    "                              bias=False)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Activation (ReLU)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)    # Apply convolution\n",
    "        x = self.bn(x)      # Apply batch normalization\n",
    "        x = self.relu(x)    # Apply ReLU activation\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Conv_ab(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0):\n",
    "        super(Conv_ab, self).__init__()\n",
    "        \n",
    "        # Convolution layer\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding=padding, \n",
    "                              bias=False)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Activation (ReLU)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)    # Apply convolution\n",
    "        x = self.bn(x)      # Apply batch normalization\n",
    "        x = self.relu(x)    # Apply ReLU activation\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "class Conv_c(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
    "        super(Conv_c, self).__init__()\n",
    "        \n",
    "        # Convolution layer\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels, \n",
    "                              kernel_size=kernel_size, \n",
    "                              stride=stride, \n",
    "                              padding=padding, \n",
    "                              bias=False)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Activation (ReLU)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)    # Apply convolution\n",
    "        x = self.bn(x)      # Apply batch normalization\n",
    "        x = self.relu(x)    # Apply ReLU activation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **Dummy input to conv layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 128, 2500, 2500])\n"
     ]
    }
   ],
   "source": [
    "# Example input output\n",
    "conv_i = Conv_i(in_channels=3, out_channels=128)\n",
    "\n",
    "# Dummy input of shape [batch_size, channels, height, width], e.g., (1, 3, 5000, 5000)\n",
    "dummy_input = torch.randn(1, 3, 5000, 5000)\n",
    "output = conv_i(dummy_input)\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_a1 Output shape: torch.Size([1, 256, 1250, 1250])\n"
     ]
    }
   ],
   "source": [
    "# Example input output\n",
    "conv_a1 = Conv_ab(in_channels=256, out_channels=256)\n",
    "# Dummy input of shape [batch_size, channels, height, width], e.g., (1, 3, 5000, 5000)\n",
    "dummy_input = torch.randn(1, 256, 1250, 1250)\n",
    "output = conv_a1(dummy_input)\n",
    "print(f\"Conv_a1 Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_b1 Output shape: torch.Size([1, 256, 625, 625])\n"
     ]
    }
   ],
   "source": [
    "conv_b1 = Conv_ab(in_channels=512, out_channels=256)\n",
    "# Dummy input of shape [batch_size, channels, height, width], e.g., (1, 3, 5000, 5000)\n",
    "dummy_input_ = torch.randn(1, 512, 625, 625)\n",
    "output_ = conv_b1(dummy_input_)\n",
    "print(f\"Conv_b1 Output shape: {output_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_c1 Output shape: torch.Size([1, 256, 313, 313])\n"
     ]
    }
   ],
   "source": [
    "#Example input output\n",
    "conv_c1 = Conv_c(in_channels=256, out_channels=256)\n",
    "# Dummy input of shape [batch_size, channels, height, width], e.g., (1, 3, 5000, 5000)\n",
    "dummy_input = torch.randn(1, 256, 625, 625)\n",
    "output = conv_c1(dummy_input)\n",
    "print(f\"Conv_c1 Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **EMB_a block**\n",
    "- Dummy MBConv block\n",
    "- Block C_out scaling factor = \"single\" or \"double\"\n",
    "- Merge cardinality type: K=1, S=1, P=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMB_a(nn.Module):\n",
    "    def __init__(self, in_channels, retainment_factor, out_channels, block_type=\"single\"):\n",
    "        super(EMB_a, self).__init__()\n",
    "        \n",
    "        self.retainment_factor = retainment_factor\n",
    "        \n",
    "        # Retainment calculation\n",
    "        retain_channels = int(in_channels * (retainment_factor / 100))\n",
    "        non_retain_channels = in_channels - retain_channels\n",
    "        \n",
    "        # Two consecutive conv blocks\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Upsampling paths (4x and 16x)\n",
    "        self.upsample_4x = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        self.upsample_16x = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # MBConv Block placeholder (define separately)\n",
    "        self.mbconv_block = self._define_mbconv_block(non_retain_channels, non_retain_channels)\n",
    "        \n",
    "        # Shuffle cardinality using group conv\n",
    "        total_channels = retain_channels + 3 * non_retain_channels  # Retain, 4x, 16x, and MBConv outputs combined\n",
    "        self.group_conv1 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.group_conv2 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        # Merge cardinality conv\n",
    "        factor = 1 if block_type == \"single\" else 2\n",
    "        self.merge_conv = nn.Conv2d(total_channels, factor * in_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "    def _define_mbconv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        retain_channels = int(x.size(1) * (self.retainment_factor / 100))\n",
    "        non_retain_channels = x.size(1) - retain_channels\n",
    "        \n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        print(f\"Retain Channels: {retain_channels}, Non-Retain Channels: {non_retain_channels}\")\n",
    "        \n",
    "        retain_part, non_retain_part = torch.split(x, [retain_channels, non_retain_channels], dim=1)\n",
    "        \n",
    "        print(f\"Retain part shape: {retain_part.shape}\")\n",
    "        print(f\"Non-retain part shape: {non_retain_part.shape}\")\n",
    "        \n",
    "        conv1_output = self.conv_block1(non_retain_part)\n",
    "        conv2_output = self.conv_block1(conv1_output)\n",
    "        \n",
    "        upsample_4x_output = self.upsample_4x(conv1_output)\n",
    "        upsample_16x_output = self.upsample_16x(conv2_output)\n",
    "        \n",
    "        # Crop the upsampled outputs to match the input size\n",
    "        upsample_4x_output = self._crop_to_input_size(upsample_4x_output, x.size(2), x.size(3))\n",
    "        upsample_16x_output = self._crop_to_input_size(upsample_16x_output, x.size(2), x.size(3))\n",
    "        \n",
    "        mbconv_output = self.mbconv_block(non_retain_part)\n",
    "        \n",
    "        combined = torch.cat([retain_part, mbconv_output, upsample_4x_output, upsample_16x_output], dim=1)\n",
    "        \n",
    "        combined = self.group_conv1(combined)\n",
    "        combined = self.group_conv2(combined)\n",
    "        \n",
    "        output = self.merge_conv(combined)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def _crop_to_input_size(self, x, target_height, target_width):\n",
    "        \"\"\"Crop tensor `x` to have the specified target height and width.\"\"\"\n",
    "        _, _, h, w = x.size()\n",
    "        crop_h = (h - target_height) // 2\n",
    "        crop_w = (w - target_width) // 2\n",
    "        return x[:, :, crop_h:crop_h + target_height, crop_w:crop_w + target_width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### **EMB_b block**\n",
    "- Dummy MBConv block\n",
    "- Block C_out scaling factor = \"single\" or \"double\"\n",
    "- Merge cardinality type: K=3, S=2, P=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMB_b(nn.Module):\n",
    "    def __init__(self, in_channels, retainment_factor, out_channels, block_type=\"single\"):\n",
    "        super(EMB_b, self).__init__()\n",
    "        \n",
    "        # Store retainment factor as a percentage\n",
    "        self.retainment_factor = retainment_factor\n",
    "        \n",
    "        # Retainment calculation\n",
    "        retain_channels = int(in_channels * (retainment_factor / 100))\n",
    "        non_retain_channels = in_channels - retain_channels\n",
    "        \n",
    "        # Two consecutive conv blocks\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Upsampling paths (4x and 16x)\n",
    "        self.upsample_4x = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        self.upsample_16x = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # MBConv Block placeholder (define separately)\n",
    "        self.mbconv_block = self._define_mbconv_block(non_retain_channels, non_retain_channels)\n",
    "        \n",
    "        # Shuffle cardinality using group conv\n",
    "        total_channels = retain_channels + 3 * non_retain_channels  # Retain, 4x, 16x, and MBConv outputs combined\n",
    "        self.group_conv1 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.group_conv2 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        # Merge cardinality conv\n",
    "        factor = 1 if block_type == \"single\" else 2\n",
    "        self.merge_conv = nn.Conv2d(total_channels, factor * in_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def _define_mbconv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        retain_channels = int(x.size(1) * (self.retainment_factor / 100))\n",
    "        non_retain_channels = x.size(1) - retain_channels\n",
    "        \n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        print(f\"Retain Channels: {retain_channels}, Non-Retain Channels: {non_retain_channels}\")\n",
    "        \n",
    "        retain_part, non_retain_part = torch.split(x, [retain_channels, non_retain_channels], dim=1)\n",
    "        \n",
    "        print(f\"Retain part shape: {retain_part.shape}\")\n",
    "        print(f\"Non-retain part shape: {non_retain_part.shape}\")\n",
    "        \n",
    "        conv1_output = self.conv_block1(non_retain_part)\n",
    "        conv2_output = self.conv_block1(conv1_output)\n",
    "        \n",
    "        upsample_4x_output = self.upsample_4x(conv1_output)\n",
    "        upsample_16x_output = self.upsample_16x(conv2_output)\n",
    "        \n",
    "        # Crop the upsampled outputs to match the input size\n",
    "        upsample_4x_output = self._crop_to_input_size(upsample_4x_output, x.size(2), x.size(3))\n",
    "        upsample_16x_output = self._crop_to_input_size(upsample_16x_output, x.size(2), x.size(3))\n",
    "        \n",
    "        mbconv_output = self.mbconv_block(non_retain_part)\n",
    "        \n",
    "        combined = torch.cat([retain_part, mbconv_output, upsample_4x_output, upsample_16x_output], dim=1)\n",
    "        \n",
    "        combined = self.group_conv1(combined)\n",
    "        combined = self.group_conv2(combined)\n",
    "        \n",
    "        output = self.merge_conv(combined)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def _crop_to_input_size(self, x, target_height, target_width):\n",
    "        \"\"\"Crop tensor `x` to have the specified target height and width.\"\"\"\n",
    "        _, _, h, w = x.size()\n",
    "        crop_h = (h - target_height) // 2\n",
    "        crop_w = (w - target_width) // 2\n",
    "        return x[:, :, crop_h:crop_h + target_height, crop_w:crop_w + target_width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **Dummy input testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 20, 2500, 2500])\n",
      "Retain Channels: 6, Non-Retain Channels: 14\n",
      "Retain part shape: torch.Size([1, 6, 2500, 2500])\n",
      "Non-retain part shape: torch.Size([1, 14, 2500, 2500])\n",
      "Output shape: torch.Size([1, 20, 2500, 2500])\n"
     ]
    }
   ],
   "source": [
    "channels = 20\n",
    "\n",
    "elan_mbconv_block = EMB_a(in_channels=channels, retainment_factor=30, out_channels=channels, block_type=\"single\")\n",
    "\n",
    "# Dummy image tensor with shape [batch_size, channels, height, width]\n",
    "dummy_image = torch.randn(1, channels, 2500, 2500) \n",
    "\n",
    "# Passing the dummy image through the ELANMBConv block\n",
    "output = elan_mbconv_block(dummy_image)\n",
    "\n",
    "# output shape\n",
    "print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 20, 2500, 2500])\n",
      "Retain Channels: 6, Non-Retain Channels: 14\n",
      "Retain part shape: torch.Size([1, 6, 2500, 2500])\n",
      "Non-retain part shape: torch.Size([1, 14, 2500, 2500])\n",
      "Output shape: torch.Size([1, 40, 1250, 1250])\n"
     ]
    }
   ],
   "source": [
    "channels = 20\n",
    "\n",
    "elan_mbconv_block = EMB_b(in_channels=channels, retainment_factor=30, out_channels=channels, block_type=\"double\")\n",
    "\n",
    "# Dummy image tensor with shape [batch_size, channels, height, width]\n",
    "dummy_image = torch.randn(1, channels, 2500, 2500) \n",
    "\n",
    "# Passing the dummy image through the ELANMBConv block\n",
    "output = elan_mbconv_block(dummy_image)\n",
    "\n",
    "# output shape\n",
    "print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **MBConv Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlockMB(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, exp=1, act=True):\n",
    "        super(ConvBlockMB, self).__init__()\n",
    "        \n",
    "        # Expansion phase (1x1 convolution)\n",
    "        exp_channels = in_channels * exp\n",
    "        self.expansion = nn.Conv2d(in_channels, exp_channels, kernel_size=1, stride=1, bias=False) if exp > 1 else nn.Identity()\n",
    "        self.bn1 = nn.BatchNorm2d(exp_channels)\n",
    "        self.act = nn.ReLU() if act else nn.Identity()\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        self.depthwise = nn.Conv2d(exp_channels, exp_channels, kernel_size, stride, padding=(kernel_size // 2), groups=exp_channels, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(exp_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.expansion(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "        \n",
    "        # Apply depthwise convolution\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "class SeBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4):\n",
    "        super(SeBlock, self).__init__()\n",
    "        reduced_channels = in_channels // reduction\n",
    "        \n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)  # Global average pooling\n",
    "        self.fc1 = nn.Conv2d(in_channels, reduced_channels, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(reduced_channels, in_channels, kernel_size=1)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        scale = self.squeeze(x)\n",
    "        scale = self.silu(self.fc1(scale))\n",
    "        scale = self.sigmoid(self.fc2(scale))\n",
    "        return x * scale\n",
    "\n",
    "class StochasticDepth(nn.Module):\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        super(StochasticDepth, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p == 0.0:\n",
    "            return x\n",
    "        keep_prob = 1 - self.p\n",
    "        mask = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < keep_prob\n",
    "        return x / keep_prob * mask\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, exp=1, reduction=4, sd_prob=0.0):\n",
    "        super(MBConv, self).__init__()\n",
    "        exp_channels = in_channels * exp\n",
    "        self.add_skip = (in_channels == out_channels) and (stride == 1)\n",
    "\n",
    "        # Expansion phase (1x1 conv if exp > 1)\n",
    "        self.conv1 = ConvBlockMB(in_channels, exp_channels, 1, 1, exp=exp)\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        self.depthwise_conv = nn.Conv2d(exp_channels, exp_channels, kernel_size, stride=stride, padding=(kernel_size // 2), groups=exp_channels, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(exp_channels)\n",
    "\n",
    "        # Squeeze-and-Excitation block\n",
    "        self.se = SeBlock(exp_channels, reduction=reduction)\n",
    "        \n",
    "        # Projection phase (1x1 convolution to project back to output channels)\n",
    "        self.conv2 = nn.Conv2d(exp_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Stochastic depth\n",
    "        self.sd = StochasticDepth(sd_prob)\n",
    "\n",
    "        # Skip connection if in_channels == out_channels and stride == 1\n",
    "        if self.add_skip:\n",
    "            self.skip_connection = nn.Identity()\n",
    "        else:\n",
    "            self.skip_connection = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "\n",
    "        # Expansion + Depthwise conv + SE block\n",
    "        x = self.conv1(x)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.se(x)\n",
    "        \n",
    "        # Project to out_channels\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # Stochastic depth and skip connection\n",
    "        if self.add_skip:\n",
    "            x = x + shortcut\n",
    "        x = self.sd(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **ELAN-MBConv block with Original MBConv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMB_A(nn.Module):\n",
    "    def __init__(self, in_channels, retainment_factor, out_channels, block_type=\"single\", exp=4, sd_prob=0.1):\n",
    "        super(EMB_A, self).__init__()\n",
    "        \n",
    "        # Store retainment factor as a percentage\n",
    "        self.retainment_factor = retainment_factor\n",
    "        \n",
    "        # Retainment calculation\n",
    "        retain_channels = int(in_channels * (retainment_factor / 100))\n",
    "        non_retain_channels = in_channels - retain_channels\n",
    "        \n",
    "        # Two consecutive conv blocks\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Upsampling paths (4x and 16x)\n",
    "        self.upsample_4x = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        self.upsample_16x = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # MBConv Block with updated, simplified code\n",
    "        self.mbconv_block = MBConv(\n",
    "            in_channels=non_retain_channels, \n",
    "            out_channels=non_retain_channels,  # Typically the output is same as input for residual blocks\n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            exp=exp, \n",
    "            sd_prob=sd_prob\n",
    "        )\n",
    "        \n",
    "        # Shuffle cardinality using group conv\n",
    "        total_channels = retain_channels + 3 * non_retain_channels  # Retain, 4x, 16x, and MBConv outputs combined\n",
    "        self.group_conv1 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.group_conv2 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        # Merge cardinality conv\n",
    "        factor = 1 if block_type == \"single\" else 2\n",
    "        self.merge_conv = nn.Conv2d(total_channels, factor * in_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split the channels based on the retainment factor\n",
    "        retain_channels = int(x.size(1) * (self.retainment_factor / 100))\n",
    "        non_retain_channels = x.size(1) - retain_channels\n",
    "        \n",
    "        retain_part, non_retain_part = torch.split(x, [retain_channels, non_retain_channels], dim=1)\n",
    "        \n",
    "        # Process non-retained part: conv -> copy -> conv again\n",
    "        conv1_output = self.conv_block1(non_retain_part)\n",
    "        conv2_output = self.conv_block1(conv1_output)\n",
    "        \n",
    "        # Upsample outputs\n",
    "        upsample_4x_output = self.upsample_4x(conv1_output)\n",
    "        upsample_16x_output = self.upsample_16x(conv2_output)\n",
    "        \n",
    "        # Resize upsampled outputs to match retain_part size (height and width)\n",
    "        upsample_4x_output = F.interpolate(upsample_4x_output, size=(retain_part.size(2), retain_part.size(3)), mode='bilinear', align_corners=False)\n",
    "        upsample_16x_output = F.interpolate(upsample_16x_output, size=(retain_part.size(2), retain_part.size(3)), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # MBConv processing\n",
    "        mbconv_output = self.mbconv_block(non_retain_part)\n",
    "        \n",
    "        # Combine outputs: retain + mbconv + 4x upsample + 16x upsample\n",
    "        combined = torch.cat([retain_part, mbconv_output, upsample_4x_output, upsample_16x_output], dim=1)\n",
    "        \n",
    "        # Shuffle cardinality (group conv)\n",
    "        combined = self.group_conv1(combined)\n",
    "        combined = self.group_conv2(combined)\n",
    "        \n",
    "        # Merge cardinality conv\n",
    "        output = self.merge_conv(combined)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMB_B(nn.Module):\n",
    "    def __init__(self, in_channels, retainment_factor, out_channels, block_type=\"single\", exp=4, sd_prob=0.1):\n",
    "        super(EMB_B, self).__init__()\n",
    "        \n",
    "        # Store retainment factor as a percentage\n",
    "        self.retainment_factor = retainment_factor\n",
    "        \n",
    "        # Retainment calculation\n",
    "        retain_channels = int(in_channels * (retainment_factor / 100))\n",
    "        non_retain_channels = in_channels - retain_channels\n",
    "        \n",
    "        # Two consecutive conv blocks\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(non_retain_channels, non_retain_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(non_retain_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Upsampling paths (4x and 16x)\n",
    "        self.upsample_4x = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        self.upsample_16x = nn.Upsample(scale_factor=16, mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # MBConv Block with updated, simplified code\n",
    "        self.mbconv_block = MBConv(\n",
    "            in_channels=non_retain_channels, \n",
    "            out_channels=non_retain_channels,  # Typically the output is same as input for residual blocks\n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            exp=exp, \n",
    "            sd_prob=sd_prob\n",
    "        )\n",
    "        \n",
    "        # Shuffle cardinality using group conv\n",
    "        total_channels = retain_channels + 3 * non_retain_channels  # Retain, 4x, 16x, and MBConv outputs combined\n",
    "        self.group_conv1 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.group_conv2 = nn.Conv2d(total_channels, total_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        # Merge cardinality conv\n",
    "        factor = 1 if block_type == \"single\" else 2\n",
    "        self.merge_conv = nn.Conv2d(total_channels, factor * in_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split the channels based on the retainment factor\n",
    "        retain_channels = int(x.size(1) * (self.retainment_factor / 100))\n",
    "        non_retain_channels = x.size(1) - retain_channels\n",
    "        \n",
    "        retain_part, non_retain_part = torch.split(x, [retain_channels, non_retain_channels], dim=1)\n",
    "        \n",
    "        # Process non-retained part: conv -> copy -> conv again\n",
    "        conv1_output = self.conv_block1(non_retain_part)\n",
    "        conv2_output = self.conv_block1(conv1_output)\n",
    "        \n",
    "        # Upsample outputs\n",
    "        upsample_4x_output = self.upsample_4x(conv1_output)\n",
    "        upsample_16x_output = self.upsample_16x(conv2_output)\n",
    "        \n",
    "        # Resize upsampled outputs to match retain_part size (height and width)\n",
    "        upsample_4x_output = F.interpolate(upsample_4x_output, size=(retain_part.size(2), retain_part.size(3)), mode='bilinear', align_corners=False)\n",
    "        upsample_16x_output = F.interpolate(upsample_16x_output, size=(retain_part.size(2), retain_part.size(3)), mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # MBConv processing\n",
    "        mbconv_output = self.mbconv_block(non_retain_part)\n",
    "        \n",
    "        # Combine outputs: retain + mbconv + 4x upsample + 16x upsample\n",
    "        combined = torch.cat([retain_part, mbconv_output, upsample_4x_output, upsample_16x_output], dim=1)\n",
    "        \n",
    "        # Shuffle cardinality (group conv)\n",
    "        combined = self.group_conv1(combined)\n",
    "        combined = self.group_conv2(combined)\n",
    "        \n",
    "        # Merge cardinality conv\n",
    "        output = self.merge_conv(combined)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "### **Dummy input testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 100, 1250, 1250])\n"
     ]
    }
   ],
   "source": [
    "channels = 100\n",
    "\n",
    "elan_mbconv_block = EMB_A(in_channels=channels, retainment_factor=50, out_channels=channels, block_type=\"single\")\n",
    "\n",
    "# Dummy image tensor with shape [batch_size, channels, height, width]\n",
    "dummy_image = torch.randn(1, channels, 1250, 1250) \n",
    "\n",
    "# Passing the dummy image through the ELANMBConv block\n",
    "output = elan_mbconv_block(dummy_image)\n",
    "\n",
    "# output shape\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 100, 625, 625])\n"
     ]
    }
   ],
   "source": [
    "channels = 50\n",
    "\n",
    "elan_mbconv_block = EMB_B(in_channels=channels, retainment_factor=50, out_channels=channels, block_type=\"double\")\n",
    "\n",
    "# Dummy image tensor with shape [batch_size, channels, height, width]\n",
    "dummy_image = torch.randn(1, channels, 1250, 1250) \n",
    "\n",
    "# Passing the dummy image through the ELANMBConv block\n",
    "output = elan_mbconv_block(dummy_image)\n",
    "\n",
    "# output shape\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Backbone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov7_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
